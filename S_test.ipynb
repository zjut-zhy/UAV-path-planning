{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ee9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'Single UAV path planning\\path planning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#开发者：Bright Fang\n",
    "#开发时间：2023/7/30 18:13\n",
    "from rl_env.path_env import RlGame\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle as pkl\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "shoplistfile_test = 'Multi-UAVs path planning/path planning/sample_indextest'  #保存文件数据所在文件的文件名'\n",
    "N_Agent=1\n",
    "M_Enemy=5\n",
    "L_Obstacle=3\n",
    "RENDER=True\n",
    "env = RlGame(n=N_Agent,m=M_Enemy,l=L_Obstacle,render=RENDER).unwrapped\n",
    "EPIOSDE_ALL=500\n",
    "TEST_EPIOSDE=100\n",
    "TRAIN_NUM = 5\n",
    "EP_LEN = 1000\n",
    "state_number=7\n",
    "action_number=env.action_space.shape[0]\n",
    "max_action = env.action_space.high[0]\n",
    "min_action = env.action_space.low[0]\n",
    "LR_A = 5e-4    # learning rate for actor\n",
    "LR_C = 1e-3    # learning rate for critic\n",
    "GAMMA = 0.9\n",
    "MemoryCapacity=20000\n",
    "Batch=128\n",
    "Switch=1\n",
    "tau = 0.0005\n",
    "\n",
    "def main():\n",
    "    run(env)\n",
    "def run(env):\n",
    "    print('随机测试中...')\n",
    "    win_times = 0\n",
    "    average_timestep=0\n",
    "    average_integral_V=0\n",
    "    average_integral_U= 0\n",
    "    all_ep_V, all_ep_U, all_ep_T = [], [], []\n",
    "    for j in range(TEST_EPIOSDE):\n",
    "        state = env.reset()\n",
    "        total_rewards = 0\n",
    "        integral_V=0\n",
    "        integral_U=0\n",
    "        for timestep in range(EP_LEN):\n",
    "            for i in range(N_Agent+M_Enemy):\n",
    "                action = env.action_space.sample()\n",
    "            new_state, reward,done,edge_r,obstacle_r,goal_r,win= env.step(action)  # 执行动作\n",
    "            if win:\n",
    "                win_times += 1\n",
    "            integral_V += state[2]\n",
    "            integral_U += abs(action).sum()\n",
    "            total_rewards += reward\n",
    "            state = new_state\n",
    "            if RENDER:\n",
    "                env.render()\n",
    "            if done:\n",
    "                break\n",
    "        average_timestep += timestep\n",
    "        average_integral_V += integral_V\n",
    "        average_integral_U += integral_U\n",
    "        print(\"Score\", total_rewards)\n",
    "        all_ep_V.append(integral_V)\n",
    "        all_ep_U.append(integral_U)\n",
    "        all_ep_T.append(timestep)\n",
    "    print('任务完成率', win_times / TEST_EPIOSDE)\n",
    "    print('平均最短飞行时间', average_timestep / TEST_EPIOSDE)\n",
    "    print('平均最短飞行路程', average_integral_V / TEST_EPIOSDE)\n",
    "    print('平均最小能量损耗', average_integral_U / TEST_EPIOSDE)\n",
    "    # env.close()\n",
    "    # d = {\"all_ep_V\": all_ep_V, \"all_ep_U\": all_ep_U, \"all_ep_T\": all_ep_T}\n",
    "    # f = open(shoplistfile_test, 'wb')  # 二进制打开，如果找不到该文件，则创建一个\n",
    "    # pkl.dump(d, f, pkl.HIGHEST_PROTOCOL)  # 写入文件\n",
    "    # f.close()\n",
    "\n",
    "    # win_times = 0\n",
    "    # average_timestep=0\n",
    "    # average_integral_V=0\n",
    "    # average_integral_U= 0\n",
    "    # all_ep_r = [[] for i in range(TRAIN_NUM)]\n",
    "    # for k in range(TRAIN_NUM):\n",
    "    #     for j in range(TEST_EPIOSDE):\n",
    "    #         state = env.reset()\n",
    "    #         total_rewards = 0\n",
    "    #         integral_V=0\n",
    "    #         integral_U=0\n",
    "    #         for timestep in range(EP_LEN):\n",
    "    #             for i in range(N_Agent+M_Enemy):\n",
    "    #                 action = env.action_space.sample()\n",
    "    #             new_state, reward,done,edge_r,obstacle_r,goal_r,win= env.step(action)  # 执行动作\n",
    "    #             if win:\n",
    "    #                 win_times += 1\n",
    "    #             integral_V += state[2]\n",
    "    #             integral_U += abs(action).sum()\n",
    "    #             total_rewards += reward\n",
    "    #             state = new_state\n",
    "    #             if RENDER:\n",
    "    #                 env.render()\n",
    "    #             if done:\n",
    "    #                 break\n",
    "    #         average_timestep += timestep\n",
    "    #         average_integral_V += integral_V\n",
    "    #         average_integral_U += integral_U\n",
    "    #         print(\"Score\", total_rewards)\n",
    "    #         all_ep_r[k].append(total_rewards)\n",
    "    #     print('任务完成率', win_times / TEST_EPIOSDE)\n",
    "    #     print('平均最短飞行时间', average_timestep / TEST_EPIOSDE)\n",
    "    #     print('平均最短飞行路程', average_integral_V / TEST_EPIOSDE)\n",
    "    #     print('平均最小能量损耗', average_integral_U / TEST_EPIOSDE)\n",
    "    #     # env.close()\n",
    "    # all_ep_r_mean = np.mean((np.array(all_ep_r)), axis=0)\n",
    "    # all_ep_r_std = np.std((np.array(all_ep_r)), axis=0)\n",
    "    # d = {\"all_ep_r_mean\": all_ep_r_mean, \"all_ep_r_std\": all_ep_r_std}\n",
    "    # f = open(shoplistfile_test, 'wb')  # 二进制打开，如果找不到该文件，则创建一个\n",
    "    # pkl.dump(d, f, pkl.HIGHEST_PROTOCOL)  # 写入文件\n",
    "    # f.close()\n",
    "    # all_ep_r_max = all_ep_r_mean + all_ep_r_std * 0.95\n",
    "    # all_ep_r_min = all_ep_r_mean - all_ep_r_std * 0.95\n",
    "    # plt.plot(np.arange(len(all_ep_r_mean)), all_ep_r_mean, label='随机策略', color='#e75840')\n",
    "    # plt.fill_between(np.arange(len(all_ep_r_mean)), all_ep_r_max, all_ep_r_min, alpha=0.6, facecolor='#e75840')\n",
    "    # plt.xlabel('Monte Carlo测试回合数')\n",
    "    # plt.ylabel('总奖励')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad3f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
